{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4cc1a1-1149-4a20-b823-32d72c2b1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# # Importing the project from a subfolder\n",
    "sys.path.append('./project')\n",
    "\n",
    "from models.transformer import Aggregator\n",
    "from models.tokenizer import Tokenizer\n",
    "from models.vggt import VGGT, unflatten_tokens\n",
    "from heads.camera_head import CameraHead\n",
    "\n",
    "from dataloader.projection import *\n",
    "from dataloader.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde3b746-51e8-46fd-9515-d5164de75243",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Aggregator(embed_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c248cd5-388b-47d1-8cd9-51a05f9c0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, S, P, C = 5, 3, 20, 64 # B events, S images per event, P tokens per image, C elements per token\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "test_input = torch.tensor(np.random.randn(B, S, P, C)).float().to(device)\n",
    "test_pos = torch.tensor(np.random.randint(1, 8, size=(B, S, P, 2))).to(device)\n",
    "test_model = test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af2a30-28d9-4f48-9f72-c0c4fafcd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output, test_idx = test_model.forward(test_input, test_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb407515-8ea4-479f-881b-3ed935f2e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49665c-b066-44be-b7cb-36d6233c51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6265db-c060-4aac-a82a-d4d7cadfc642",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, H = 5, 16 # B total patches, each image a HxH square\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "test_input = torch.tensor(np.random.randn(B, H, H)).float().to(device)\n",
    "test_input = test_input.view(B, 1, H, H)\n",
    "test_model = test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073427e9-2491-4c85-a1dc-bcb72a18adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = test_model.forward(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3956d-0d8d-4c41-b1e9-438e269955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f8e4c-ace3-4b25-abeb-4679e9ecc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.view(5, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c046e-fd28-4228-8306-77da9838454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenizer = Tokenizer()\n",
    "test_aggregator = Aggregator(embed_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edb8c8-09f8-4fc5-9379-5444044b5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, S, P, H = 1, 3, 5, 16 # B events, S images per event, P patches per image, HxH patches\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "test_input = torch.tensor(np.random.randn(B, S, P, H, H)).float().to(device)\n",
    "test_pos = torch.tensor(np.random.randint(1, H+1, size=(B, S, P, 2))).to(device)\n",
    "test_tokenizer, test_aggregator = test_tokenizer.to(device), test_aggregator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995c411-e1bf-47c6-8c29-d1e0eb5ddf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple flattening for this test. In the real case this would involve recording the sequence lengths\n",
    "test_tokens = test_tokenizer.forward(test_input.view(B*S*P, H, H)).view(B, S, P, 256)\n",
    "test_output, test_idx = test_aggregator.forward(test_tokens, test_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4338d-3a61-4d3c-8ae3-f8bca25c723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0fed78-58ae-41d0-9477-1aab5991f1a3",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c79507-b700-4d04-be14-21d7c708784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset as previously demonstrated, also get device\n",
    "path = \"/sdf/home/y/youngsam/data/dune/larnet/h5/DataAccessExamples/tutorial_example_v1.h5\"\n",
    "\n",
    "dataset = Dataset(path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879d5676-e661-4d76-b0ec-9604593c2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a sample\n",
    "sample, _, rotations = dataset.choose_events(10, 3)\n",
    "patch_counts, all_coords, all_patches = stack_patches(sample)\n",
    "patch_counts = torch.Tensor(patch_counts).int().to(device)\n",
    "all_coords = torch.Tensor(all_coords).int().to(device)\n",
    "all_patches = torch.Tensor(all_patches).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ecb86da-ad72-44fd-8cfb-eaea1cc0bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = VGGT()\n",
    "test_model = test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed9b08ce-1586-4c93-ae4d-0b48ce4b1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, test_output, patch_start_idx = test_model(patch_counts, all_coords, all_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a6bd2f-75a0-4197-a516-853cac81cb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, torch.Size([10, 3, 55, 512]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_output), test_output[-1].shape\n",
    "# 24 blocks, results from every block; final result is NxSx(P+5)x(2*D)\n",
    "# P+5 because 1 camera token and 4 register tokens added\n",
    "# D*2 because ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a133cbc-5751-4ab2-928d-b987d64eb941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"pose_enc\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f409d1-d167-4011-8bca-b78e4688c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quaternions = np.array([[r.as_quat() for r in row] for row in rotations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbfe588c-ce64-488f-90ab-0764c071914f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quaternions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d690dcab-83ce-474e-b47a-0923cd51e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "quaternion_tensor = torch.tensor(quaternions).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5287007a-a323-4fa6-80b4-e1c566bad425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6238, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.square(predictions[\"pose_enc\"] - quaternion_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a47a94-ebbe-4823-8272-0117f66dbe28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
